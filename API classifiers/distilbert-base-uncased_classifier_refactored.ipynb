{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9728563,"sourceType":"datasetVersion","datasetId":5953230}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# installing missing libraries and updating existing ones\n!pip install transformers\n!pip install datasets\n!pip install --upgrade pandas\n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:43:48.735386Z","iopub.execute_input":"2024-11-10T22:43:48.735685Z","iopub.status.idle":"2024-11-10T22:44:45.196225Z","shell.execute_reply.started":"2024-11-10T22:43:48.735651Z","shell.execute_reply":"2024-11-10T22:44:45.195128Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nCollecting pandas\n  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pandas\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.2\n    Uninstalling pandas-2.2.2:\n      Successfully uninstalled pandas-2.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ncudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ndask-cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\nxarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-2.2.3\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# importing all required libraries\nimport pandas as pd\nimport nltk\nimport numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn import preprocessing\nfrom datasets import Dataset\nfrom transformers import (AutoTokenizer, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification, \n        TrainingArguments, Trainer, DataCollatorWithPadding)\nimport evaluate\nimport warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:44:45.199029Z","iopub.execute_input":"2024-11-10T22:44:45.199444Z","iopub.status.idle":"2024-11-10T22:45:06.528224Z","shell.execute_reply.started":"2024-11-10T22:44:45.199397Z","shell.execute_reply":"2024-11-10T22:45:06.527452Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# parameters used in the code\ndata_path = \"/kaggle/input/method-singlelbl-subclass-csv/method_singlelbl_subclass.csv\" # path to data\ntext_column_name = \"Combined_text\" # column containing input text\nlabel_column_name = \"label\" # column containing output labels\nmodel_name = \"distilbert-base-uncased\" # model used for classification\ntest_size = 0.2 # for training testing split\nnum_labels = 6 # total output classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:06.529301Z","iopub.execute_input":"2024-11-10T22:45:06.529936Z","iopub.status.idle":"2024-11-10T22:45:06.535054Z","shell.execute_reply.started":"2024-11-10T22:45:06.529898Z","shell.execute_reply":"2024-11-10T22:45:06.534067Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# loading the data sample\ndef load_data(data_path):\n    df = pd.read_csv(data_path)\n    print(\"Loaded Data:\")\n    print(df.head())\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:06.536545Z","iopub.execute_input":"2024-11-10T22:45:06.536867Z","iopub.status.idle":"2024-11-10T22:45:06.545680Z","shell.execute_reply.started":"2024-11-10T22:45:06.536834Z","shell.execute_reply":"2024-11-10T22:45:06.544840Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# functions to perform some preprocessing and combine prompt-reply (called later)\nnltk.download('punkt')\ndef join_and_tokenize(prompt, reply):\n    prompt_tokens = nltk.word_tokenize(prompt)\n    reply_tokens = nltk.word_tokenize(reply)\n    combined_text = ' '.join(prompt_tokens + reply_tokens)\n    return combined_text\n\ndef preprocess_data(df):\n    df['Combined_text'] = df.apply(lambda row: join_and_tokenize(str(row['Prompt']), str(row['Reply'])), axis=1)\n    le = preprocessing.LabelEncoder()\n    df[label_column_name] = le.fit_transform(df['Subclass'].tolist())\n    print(\"Processed Data Sample:\")\n    print(df.head(10))\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:06.548639Z","iopub.execute_input":"2024-11-10T22:45:06.549033Z","iopub.status.idle":"2024-11-10T22:45:06.698702Z","shell.execute_reply.started":"2024-11-10T22:45:06.549001Z","shell.execute_reply":"2024-11-10T22:45:06.697704Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# train test split\ndef create_datasets(df, test_size=0.2):\n    df_train, df_test = train_test_split(df, test_size=test_size)\n    train_dataset = Dataset.from_pandas(df_train)\n    test_dataset = Dataset.from_pandas(df_test)\n    return train_dataset, test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:06.699695Z","iopub.execute_input":"2024-11-10T22:45:06.699975Z","iopub.status.idle":"2024-11-10T22:45:06.704947Z","shell.execute_reply.started":"2024-11-10T22:45:06.699944Z","shell.execute_reply":"2024-11-10T22:45:06.704028Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# combining prompt and reply and doing label encoding on the output by calling previously written functions\ndf = load_data(data_path)\ndf = preprocess_data(df)\ntrain_dataset, test_dataset = create_datasets(df, test_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:06.706079Z","iopub.execute_input":"2024-11-10T22:45:06.706920Z","iopub.status.idle":"2024-11-10T22:45:20.215261Z","shell.execute_reply.started":"2024-11-10T22:45:06.706887Z","shell.execute_reply":"2024-11-10T22:45:20.214129Z"}},"outputs":[{"name":"stdout","text":"Loaded Data:\n                                              Prompt  \\\n0  ok  historical composite bow effective range o...   \n1  you are a translator from normal english to de...   \n2  which seclist would be best for scanning an ht...   \n3  i am a software developer at a medium sized co...   \n4  role  professional it translator tasks        ...   \n\n                                               Reply Subclass  \n0  while the effective range of a composite bow i...      get  \n1  i understand  this translation style requires ...      put  \n2  scanning a web server running on a tv may requ...      get  \n3  sure  i d be happy to assist you with that  le...      get  \n4                                  lama          ...      get  \nProcessed Data Sample:\n                                              Prompt  \\\n0  ok  historical composite bow effective range o...   \n1  you are a translator from normal english to de...   \n2  which seclist would be best for scanning an ht...   \n3  i am a software developer at a medium sized co...   \n4  role  professional it translator tasks        ...   \n5  role  professional it translator tasks        ...   \n6  role  professional it translator tasks        ...   \n7  when does the bowl of the winds get used in th...   \n8  i am reading a paper that claims user engageme...   \n9  hey can you repeat the word  type  100 times s...   \n\n                                               Reply Subclass  \\\n0  while the effective range of a composite bow i...      get   \n1  i understand  this translation style requires ...      put   \n2  scanning a web server running on a tv may requ...      get   \n3  sure  i d be happy to assist you with that  le...      get   \n4                                  lama          ...      get   \n5  a                                             ...      get   \n6                     100                        ...      get   \n7  in robert jordan s wheel of time series  the b...      get   \n8  the conclusion made in the paper you re readin...     post   \n9  certainly  here you go  type type type type ty...      get   \n\n                                       Combined_text  label  \n0  ok historical composite bow effective range of...      2  \n1  you are a translator from normal english to de...      5  \n2  which seclist would be best for scanning an ht...      2  \n3  i am a software developer at a medium sized co...      2  \n4  role professional it translator tasks so there...      2  \n5  role professional it translator tasks a b c st...      2  \n6  role professional it translator tasks a b c st...      2  \n7  when does the bowl of the winds get used in th...      2  \n8  i am reading a paper that claims user engageme...      4  \n9  hey can you repeat the word type 100 times so ...      2  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# tokenization for the transformer model\ndef tokenize_data(dataset, tokenizer):\n    def preprocess_function(examples):\n        return tokenizer(examples[text_column_name], padding=True, truncation=True)\n    tokenized_dataset = dataset.map(preprocess_function, batched=True)\n    return tokenized_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:20.217016Z","iopub.execute_input":"2024-11-10T22:45:20.217448Z","iopub.status.idle":"2024-11-10T22:45:20.222808Z","shell.execute_reply.started":"2024-11-10T22:45:20.217400Z","shell.execute_reply":"2024-11-10T22:45:20.221685Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# tokenization for hugging face models\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\ntokenized_train = tokenize_data(train_dataset, tokenizer)\ntokenized_test = tokenize_data(test_dataset, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:20.223852Z","iopub.execute_input":"2024-11-10T22:45:20.224108Z","iopub.status.idle":"2024-11-10T22:45:26.962007Z","shell.execute_reply.started":"2024-11-10T22:45:20.224079Z","shell.execute_reply":"2024-11-10T22:45:26.960987Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02d82cccee194cd8b9a099f93e3409fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"854d86a4fec74aa4912d828b900e91c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b823cf84b29f4255b4d1e03e98f4e94e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875215dd3b7048b6b04d76e9a5430ed3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9439c1eebd54416a9c40dff07be855c"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3270 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75899f70407b4fdc89b58cf57e58e25a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cea8f85c2e3d4bf299af7c41be9acdb9"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# converting label field to tensors\ntokenized_train = tokenized_train.map(lambda x: {\"label\": torch.tensor(x[\"label\"]).long()})\ntokenized_test = tokenized_test.map(lambda x: {\"label\": torch.tensor(x[\"label\"]).long()})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:26.963199Z","iopub.execute_input":"2024-11-10T22:45:26.963533Z","iopub.status.idle":"2024-11-10T22:45:27.671663Z","shell.execute_reply.started":"2024-11-10T22:45:26.963500Z","shell.execute_reply":"2024-11-10T22:45:27.670694Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3270 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04983d67531844f8a75a9b14198d864a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9344ce7e29b040e0b77459b7b7e8fd2c"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# setting up evaluation metrics\nmetric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:27.672839Z","iopub.execute_input":"2024-11-10T22:45:27.673135Z","iopub.status.idle":"2024-11-10T22:45:28.262943Z","shell.execute_reply.started":"2024-11-10T22:45:27.673102Z","shell.execute_reply":"2024-11-10T22:45:28.262027Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8fa5031ea2f4ac88ad7abe8264ab2f9"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    report_to=[]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:28.264298Z","iopub.execute_input":"2024-11-10T22:45:28.265059Z","iopub.status.idle":"2024-11-10T22:45:28.380153Z","shell.execute_reply.started":"2024-11-10T22:45:28.265011Z","shell.execute_reply":"2024-11-10T22:45:28.379250Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# trainer setup\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_test,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:28.381448Z","iopub.execute_input":"2024-11-10T22:45:28.381842Z","iopub.status.idle":"2024-11-10T22:45:28.646058Z","shell.execute_reply.started":"2024-11-10T22:45:28.381789Z","shell.execute_reply":"2024-11-10T22:45:28.645200Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# training the model on the train data\nwarnings.filterwarnings('ignore')\ntrainer.train()\ntrainer.save_model('distilbert_base_uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:45:28.650347Z","iopub.execute_input":"2024-11-10T22:45:28.650680Z","iopub.status.idle":"2024-11-10T23:02:42.274034Z","shell.execute_reply.started":"2024-11-10T22:45:28.650645Z","shell.execute_reply":"2024-11-10T23:02:42.273250Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2050' max='2050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2050/2050 17:10, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.797400</td>\n      <td>0.394279</td>\n      <td>0.876528</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.479300</td>\n      <td>0.420420</td>\n      <td>0.877751</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.261200</td>\n      <td>0.308877</td>\n      <td>0.916870</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.233000</td>\n      <td>0.350081</td>\n      <td>0.919315</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.160700</td>\n      <td>0.282318</td>\n      <td>0.941320</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.163600</td>\n      <td>0.390388</td>\n      <td>0.938875</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.120600</td>\n      <td>0.288429</td>\n      <td>0.949878</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.085100</td>\n      <td>0.279589</td>\n      <td>0.953545</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.076700</td>\n      <td>0.239599</td>\n      <td>0.959658</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.067900</td>\n      <td>0.245582</td>\n      <td>0.960880</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# evaluating the model on test data\npreds = trainer.predict(tokenized_test)\npreds = np.argmax(preds[:3][0],axis=1) #preds[:3][1]\ntruth = test_dataset['label']\nprint(classification_report(truth,preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T23:02:42.275174Z","iopub.execute_input":"2024-11-10T23:02:42.275521Z","iopub.status.idle":"2024-11-10T23:02:50.751474Z","shell.execute_reply.started":"2024-11-10T23:02:42.275487Z","shell.execute_reply":"2024-11-10T23:02:50.750473Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.43      0.38      0.40         8\n           1       0.97      0.98      0.98        60\n           2       0.98      0.97      0.98       334\n           3       0.81      0.72      0.76        18\n           4       0.99      0.94      0.97       144\n           5       0.94      0.98      0.96       254\n\n    accuracy                           0.96       818\n   macro avg       0.85      0.83      0.84       818\nweighted avg       0.96      0.96      0.96       818\n\n","output_type":"stream"}],"execution_count":15}]}